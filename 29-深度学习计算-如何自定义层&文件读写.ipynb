{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12eeb556",
   "metadata": {},
   "source": [
    "1.自定义层：\n",
    "   * 带参数的层\n",
    "   * 不带参数的层\n",
    "\n",
    "***\n",
    "2.文件读写\n",
    "   * 加载和保存张量\n",
    "   * 加载和保存模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25cb322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不带参数的层\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, X):\n",
    "        return X - X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "242c20f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2., -1.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 验证一下\n",
    "layer = CenteredLayer()\n",
    "layer(torch.FloatTensor([1, 2, 3, 4, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73d25719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 现在，我们可以将层作为组件合并到构建更复杂的模型中。\n",
    "net = nn.Sequential(nn.Linear(8, 128), CenteredLayer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4ed1c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = net(torch.rand(4, 8))\n",
    "Y.mean()\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c72434e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 带参数的层\n",
    "\n",
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_units, units):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_units, units))\n",
    "        self.bias = nn.Parameter(torch.randn(units,))\n",
    "    def forward(self, X):\n",
    "        linear = torch.matmul(X, self.weight.data) + self.bias.data\n",
    "        return F.relu(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82b4a3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.6468, -0.3709,  0.8210],\n",
       "        [ 0.0276, -0.4635, -0.7936],\n",
       "        [-0.2383, -0.1799, -0.1329],\n",
       "        [ 0.0879,  0.2967,  3.2110],\n",
       "        [-2.8279,  1.3314, -0.0485]], requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 实例化\n",
    "linear = MyLinear(5, 3)\n",
    "linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b42b380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 我们还可以使用自定义层构建模型\n",
    "net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))\n",
    "net(torch.rand(2, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a1c2472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 文件读写部分：\n",
    "# 对于单个张量，我们可以直接调用load和save函数分别读写\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "x = torch.arange(4)\n",
    "torch.save(x, 'x-file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "045c9895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = torch.load('x-file')\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "591d9c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 我们可以存储一个张量列表，然后把它们读回内存。\n",
    "y = torch.zeros(4)\n",
    "torch.save([x, y],'x-files')\n",
    "x2, y2 = torch.load('x-files')\n",
    "(x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29f2998c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 写入或读取从字符串映射到张量的字典\n",
    "mydict = {'x': x, 'y': y}\n",
    "torch.save(mydict, 'mydict')\n",
    "mydict2 = torch.load('mydict')\n",
    "mydict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69b8d45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hidden.weight',\n",
       "              tensor([[ 0.1414,  0.1394,  0.1123,  ...,  0.1445,  0.1443,  0.2183],\n",
       "                      [ 0.0397,  0.2163, -0.1119,  ...,  0.0144,  0.0573, -0.1374],\n",
       "                      [ 0.1329, -0.0665, -0.2027,  ...,  0.0693,  0.1316, -0.1639],\n",
       "                      ...,\n",
       "                      [ 0.0669, -0.1595,  0.1582,  ...,  0.0316, -0.1544,  0.1534],\n",
       "                      [-0.1199,  0.1117,  0.1042,  ..., -0.0875, -0.0185, -0.0969],\n",
       "                      [-0.1175, -0.0018,  0.0047,  ..., -0.2157,  0.1471,  0.0033]])),\n",
       "             ('hidden.bias',\n",
       "              tensor([ 0.0686,  0.1704,  0.0100,  0.1763,  0.1053, -0.0825,  0.0187,  0.0017,\n",
       "                      -0.2133,  0.1802, -0.1089,  0.1716,  0.0216, -0.1982, -0.0934, -0.0977,\n",
       "                       0.1516,  0.0691, -0.2066, -0.0339, -0.0680,  0.2016, -0.0111,  0.1381,\n",
       "                       0.0830,  0.0088,  0.1984, -0.0877, -0.0884, -0.2093, -0.1989, -0.2088,\n",
       "                      -0.0362,  0.1941,  0.0824,  0.0912,  0.1913,  0.1653,  0.1852, -0.0561,\n",
       "                       0.0992, -0.0857,  0.0842, -0.1262, -0.1677, -0.0236,  0.1475,  0.1886,\n",
       "                      -0.0716,  0.0504, -0.1921, -0.0882, -0.0303, -0.1296,  0.2102,  0.1779,\n",
       "                      -0.2156, -0.1268, -0.2170,  0.0702, -0.0656,  0.0396,  0.0533,  0.2062,\n",
       "                       0.1820, -0.0791, -0.1638, -0.2180, -0.1191, -0.1587, -0.0725, -0.0901,\n",
       "                       0.0290,  0.1881, -0.1311,  0.0324,  0.1025, -0.2228,  0.0470,  0.1864,\n",
       "                      -0.0686, -0.2147, -0.0773,  0.1345,  0.0316, -0.0673,  0.0061, -0.0039,\n",
       "                       0.1939,  0.1900, -0.0081, -0.0110, -0.0998, -0.2198, -0.1159,  0.1391,\n",
       "                       0.1631, -0.0938,  0.0127,  0.1769, -0.2053,  0.0540, -0.1181, -0.0141,\n",
       "                       0.1192, -0.0749,  0.1035,  0.0070, -0.0835, -0.2140,  0.2180, -0.1413,\n",
       "                      -0.1306,  0.1772, -0.1210, -0.0738,  0.1260,  0.0345, -0.0911,  0.0177,\n",
       "                      -0.1896, -0.1422, -0.0106, -0.0936, -0.0953, -0.2027,  0.1347,  0.2020,\n",
       "                      -0.1160,  0.2137, -0.1686,  0.0163,  0.0870,  0.1017,  0.0910, -0.1271,\n",
       "                      -0.0722,  0.1092,  0.0824, -0.0955,  0.1210,  0.1356,  0.0086, -0.2097,\n",
       "                       0.2085,  0.0815,  0.1185, -0.0035, -0.1677,  0.0928, -0.0599, -0.2013,\n",
       "                      -0.0907, -0.1654, -0.1917,  0.0461,  0.1752,  0.1340,  0.0025,  0.1013,\n",
       "                      -0.0381, -0.0580,  0.0540,  0.1223,  0.1068, -0.1808,  0.1712, -0.2162,\n",
       "                      -0.1422,  0.2177,  0.1342,  0.0055, -0.0034,  0.1852,  0.0241, -0.1438,\n",
       "                      -0.1633, -0.1194, -0.2102,  0.1450, -0.2133,  0.1080, -0.2008,  0.2186,\n",
       "                       0.0241,  0.0665, -0.0456,  0.0371,  0.1790,  0.0127,  0.1510,  0.1503,\n",
       "                      -0.1534, -0.0615,  0.1624,  0.0918, -0.1880,  0.0707, -0.0007, -0.0897,\n",
       "                      -0.0829,  0.0962,  0.1218,  0.1907,  0.0055,  0.1026, -0.1315, -0.1823,\n",
       "                       0.0135, -0.1919, -0.0811,  0.0832,  0.1782,  0.0487,  0.0697, -0.1536,\n",
       "                       0.1893, -0.0524, -0.1449,  0.0261, -0.1176, -0.0968,  0.1735,  0.1918,\n",
       "                       0.1784,  0.2165,  0.0873, -0.1330, -0.1380, -0.1949, -0.0187, -0.0207,\n",
       "                       0.1511, -0.0124,  0.0396,  0.0375, -0.0960, -0.0563, -0.0737, -0.2202,\n",
       "                      -0.0640, -0.2038, -0.0145,  0.1390,  0.1226,  0.1472,  0.0604,  0.0227,\n",
       "                       0.2071, -0.2038,  0.0259,  0.0368,  0.0904,  0.0943,  0.0976, -0.2188])),\n",
       "             ('output.weight',\n",
       "              tensor([[-0.0408,  0.0305,  0.0432,  ...,  0.0460, -0.0030,  0.0523],\n",
       "                      [ 0.0409, -0.0272, -0.0037,  ...,  0.0370,  0.0170,  0.0018],\n",
       "                      [ 0.0430, -0.0135,  0.0283,  ..., -0.0423,  0.0270, -0.0506],\n",
       "                      ...,\n",
       "                      [-0.0311, -0.0108, -0.0436,  ...,  0.0370, -0.0097,  0.0209],\n",
       "                      [-0.0129, -0.0448,  0.0184,  ...,  0.0207,  0.0233, -0.0390],\n",
       "                      [-0.0362,  0.0457, -0.0259,  ...,  0.0594,  0.0383,  0.0596]])),\n",
       "             ('output.bias',\n",
       "              tensor([-0.0553,  0.0492,  0.0273, -0.0185,  0.0195,  0.0541,  0.0337, -0.0548,\n",
       "                      -0.0348,  0.0356]))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载和保存模型参数\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "net = MLP()\n",
    "X = torch.randn(size=(2, 20))\n",
    "Y = net(X)\n",
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f364c035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 我们将模型的参数存储为一个叫做“mlp.params”的文件。\n",
    "torch.save(net.state_dict(), 'mlp.params')\n",
    "clone = MLP()\n",
    "clone.load_state_dict(torch.load('mlp.params'))\n",
    "clone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c947a5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_clone = clone(X)\n",
    "Y_clone == Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae2ac4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
